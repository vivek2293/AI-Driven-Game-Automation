{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a96985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mss import mss # screen grabber\n",
    "import pyautogui\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk # screen replay\n",
    "import time # For delay\n",
    "import cv2\n",
    "import random \n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ecd770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get screen region co-ordinate manually\n",
    "# import pyautogui\n",
    "# import time\n",
    "\n",
    "# # Get mouse position\n",
    "# while True:\n",
    "#     brk = input(\"Press Enter to get position or any other key to break: \")\n",
    "#     if(brk):\n",
    "#         break;\n",
    "#     x, y = pyautogui.position()\n",
    "#     print(f\"Current mouse position: x={x}, y={y}\")\n",
    "#     time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18f0dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check screen region \n",
    "# from mss import mss\n",
    "# from PIL import Image\n",
    "# # x=81, y=32\n",
    "# # x=1343, y=744\n",
    "# # Get Screenshot\n",
    "# region = {'left': 80, 'top': 32, 'width': 950, 'height': 531}\n",
    "# with mss() as sct:\n",
    "#     screenshot = sct.grab(region)\n",
    "#     img = Image.frombytes('RGB', screenshot.size, screenshot.rgb)\n",
    "#     img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a290ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tutorial detection\n",
    "# import time\n",
    "# import mss\n",
    "# import pyautogui\n",
    "\n",
    "# # aim_detect = pyautogui.locateOnScreen(\"./images/aim_complete.png\", confidence=0.5)\n",
    "# # print(aim_detect)\n",
    "\n",
    "# aim_detect = pyautogui.locateCenterOnScreen(\"./images/aim_complete.png\", confidence=0.6)\n",
    "# pyautogui.moveTo(aim_detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1df3c659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Color range selector code\n",
    "# # https://stackoverflow.com/questions/10948589/choosing-the-correct-upper-and-lower-hsv-boundaries-for-color-detection-withcv\n",
    "\n",
    "# def nothing(x):\n",
    "#     pass\n",
    "\n",
    "# # Load image\n",
    "# image = cv2.imread(\"./images/game_over_screen.png\")\n",
    "\n",
    "# # Create a window\n",
    "# cv2.namedWindow('image')\n",
    "\n",
    "# # Create trackbars for color change\n",
    "# # Hue is from 0-179 for Opencv\n",
    "# cv2.createTrackbar('HMin', 'image', 0, 179, nothing)\n",
    "# cv2.createTrackbar('SMin', 'image', 0, 255, nothing)\n",
    "# cv2.createTrackbar('VMin', 'image', 0, 255, nothing)\n",
    "# cv2.createTrackbar('HMax', 'image', 0, 179, nothing)\n",
    "# cv2.createTrackbar('SMax', 'image', 0, 255, nothing)\n",
    "# cv2.createTrackbar('VMax', 'image', 0, 255, nothing)\n",
    "\n",
    "# # Set default value for Max HSV trackbars\n",
    "# cv2.setTrackbarPos('HMax', 'image', 179)\n",
    "# cv2.setTrackbarPos('SMax', 'image', 255)\n",
    "# cv2.setTrackbarPos('VMax', 'image', 255)\n",
    "\n",
    "# # Initialize HSV min/max values\n",
    "# hMin = sMin = vMin = hMax = sMax = vMax = 0\n",
    "# phMin = psMin = pvMin = phMax = psMax = pvMax = 0\n",
    "\n",
    "# while(1):\n",
    "#     # Get current positions of all trackbars\n",
    "#     hMin = cv2.getTrackbarPos('HMin', 'image')\n",
    "#     sMin = cv2.getTrackbarPos('SMin', 'image')\n",
    "#     vMin = cv2.getTrackbarPos('VMin', 'image')\n",
    "#     hMax = cv2.getTrackbarPos('HMax', 'image')\n",
    "#     sMax = cv2.getTrackbarPos('SMax', 'image')\n",
    "#     vMax = cv2.getTrackbarPos('VMax', 'image')\n",
    "\n",
    "#     # Set minimum and maximum HSV values to display\n",
    "#     lower = np.array([hMin, sMin, vMin])\n",
    "#     upper = np.array([hMax, sMax, vMax])\n",
    "\n",
    "#     # Convert to HSV format and color threshold\n",
    "#     hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "#     mask = cv2.inRange(hsv, lower, upper)\n",
    "#     result = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "#     # Print if there is a change in HSV value\n",
    "#     if((phMin != hMin) | (psMin != sMin) | (pvMin != vMin) | (phMax != hMax) | (psMax != sMax) | (pvMax != vMax) ):\n",
    "#         print(\"(hMin = %d , sMin = %d, vMin = %d), (hMax = %d , sMax = %d, vMax = %d)\" % (hMin , sMin , vMin, hMax, sMax , vMax))\n",
    "#         phMin = hMin\n",
    "#         psMin = sMin\n",
    "#         pvMin = vMin\n",
    "#         phMax = hMax\n",
    "#         psMax = sMax\n",
    "#         pvMax = vMax\n",
    "\n",
    "#     # Display result image\n",
    "#     cv2.imshow('image', result)\n",
    "#     if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffc92fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pattern matcher for aim circle\n",
    "\n",
    "# def match_image(pattern_url, image_url):\n",
    "#     tar = cv2.imread(pattern_url)\n",
    "#     tar_gray = cv2.cvtColor(tar, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "#     # Convert to HSV Color Space:\n",
    "#     image = cv2.imread(image_url)\n",
    "#     hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "#     # Define a Green Color Range:\n",
    "#     lower_green = np.array([50, 218, 183])  # Adjust these values based on your specific shade of green\n",
    "#     upper_green = np.array([175, 255, 255])\n",
    "#     mask = cv2.inRange(hsv_image, lower_green, upper_green)\n",
    "\n",
    "#     # Apply the Mask:\n",
    "#     green_areas = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "#     # Grayscale and blur to remove noise:\n",
    "#     gray_image = cv2.cvtColor(green_areas, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     # Template Matching:\n",
    "#     result = cv2.matchTemplate(gray_image, tar_gray, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "\n",
    "#     threshold = 0.3\n",
    "#     loc = np.where(result >= threshold)\n",
    "\n",
    "#     for pt in zip(*loc[::-1]):\n",
    "#         cv2.rectangle(image, pt, (pt[0] + tar.shape[1], pt[1] + tar.shape[0]), (0, 0, 255), 2)\n",
    "    \n",
    "#     return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7ca9b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display detections\n",
    "# result_images = []\n",
    "# for i in range(1, 7):\n",
    "    # img = match_image(\"./images/aim_complete.png\", \"./Aim_train/\"+str(i)+\".png\")\n",
    "#     result_images.append(img)\n",
    "\n",
    "# for idx, result_image in enumerate(result_images, start=1):\n",
    "#     cv2.imshow(f\"Matching Result {idx}\", result_image)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f0ddeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Movements control:\n",
    "# steer_up_key = \"W\"\n",
    "# steer_down_key = \"S\"\n",
    "# steer_right_key = \"R\"\n",
    "# steer_left_key = \"L\"\n",
    "\n",
    "# view_up_key = \"I\"\n",
    "# view_down_key = \"K\"\n",
    "# view_left_key = \"J\"\n",
    "# view_right_key = \"L\"\n",
    "\n",
    "# def rotate_right_down():\n",
    "#     pyautogui.keyDown(\"L\")\n",
    "    \n",
    "# def rotate_right_up():\n",
    "#     pyautogui.keyUp(\"L\")\n",
    "    \n",
    "# def steer_up():\n",
    "#     pyautogui.keyDown(\"W\")\n",
    "#     time.sleep(0.1)\n",
    "#     pyautogui.keyUp(\"W\")\n",
    "\n",
    "# def steer_down():\n",
    "#     pyautogui.keyDown(\"S\")\n",
    "#     time.sleep(0.1)\n",
    "#     pyautogui.keyUp(\"S\")\n",
    "\n",
    "# # Fire keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "374676b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pattern matcher for aim circle\n",
    "# def match_live_image(pattern, image_live):\n",
    "#     # Target is in gray already preprocessed beforehand\n",
    "#     pattern_cv2 = np.array(pattern)[:, :, ::-1].copy()\n",
    "#     tar_gray = cv2.cvtColor(pattern_cv2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "#     # Convert to HSV Color Space:\n",
    "#     image_live_cv2 = np.array(image_live)[:, :, ::-1].copy()\n",
    "#     hsv_image = cv2.cvtColor(image_live_cv2, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "#     # Define a Green Color Range:\n",
    "#     lower_green = np.array([50, 218, 183])  # Adjust these values based on your specific shade of green\n",
    "#     upper_green = np.array([175, 255, 255])\n",
    "#     mask = cv2.inRange(hsv_image, lower_green, upper_green)\n",
    "#     # Apply the Mask:\n",
    "#     green_areas = cv2.bitwise_and(image_live_cv2, image_live_cv2, mask=mask)\n",
    "    \n",
    "#     # Grayscale and blur to remove noise:\n",
    "#     gray_image = cv2.cvtColor(green_areas, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "#     # Template Matching:\n",
    "#     result = cv2.matchTemplate(gray_image, tar_gray, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "\n",
    "#     threshold = 0.27\n",
    "#     is_found = False\n",
    "#     loc = np.where(result >= threshold)\n",
    "    \n",
    "#     # Now Aiming is complete fire down\n",
    "#     if(len(loc[0]) > 0):\n",
    "#         is_found = True\n",
    "    \n",
    "    \n",
    "#     for pt in zip(*loc[::-1]):\n",
    "#         cv2.rectangle(image_live_cv2, pt, (pt[0] + pattern_cv2.shape[1], pt[1] + pattern_cv2.shape[0]), (0, 0, 255), 2)\n",
    "    \n",
    "#     image_live_cv2 = image_live_cv2[:, :, ::-1].copy()\n",
    "#     return image_live_cv2, is_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5505318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Real-time player\n",
    "# # x=81, y=32\n",
    "# # x=1343, y=744\n",
    "# region = {'left': 80, 'top': 32, 'width': 950, 'height': 531}\n",
    "\n",
    "# # Create a tkinter window\n",
    "# root = tk.Tk()\n",
    "# root.title(\"Replay\")\n",
    "# initial_x = 81\n",
    "# initial_y = 536\n",
    "# root.geometry(f\"+{initial_x}+{initial_y}\")\n",
    "\n",
    "# # Why need label??\n",
    "# # Create a label to display the image in the tkinter window\n",
    "# label = tk.Label(root)\n",
    "# label.pack()\n",
    "\n",
    "# def update_image(label, img):\n",
    "#     image_tk = ImageTk.PhotoImage(img)\n",
    "#     label.configure(image=image_tk)\n",
    "#     label.image = image_tk\n",
    "\n",
    "# # Initialize\n",
    "# keep_playing = True;\n",
    "# def exit_loop(event):            \n",
    "#     global keep_playing\n",
    "#     keep_playing = False\n",
    "\n",
    "# root.bind('<`>', exit_loop)\n",
    "\n",
    "# # VARIABLES\n",
    "# pattern = Image.open(\"./images/aim_complete.png\")\n",
    "# fps = 0\n",
    "# wc1 = 8\n",
    "# weapon_cool_1 = wc1\n",
    "# is_notfound_cnt = 0\n",
    "# is_rotating_right = False\n",
    "# steer_vert = 0\n",
    "\n",
    "# def update_variables(time):\n",
    "#     global weapon_cool_1\n",
    "#     weapon_cool_1 = max(0, weapon_cool_1 - time)\n",
    "\n",
    "# # Image as video\n",
    "# while keep_playing:\n",
    "#     with mss() as sct:\n",
    "#         screenshot = sct.grab(region)\n",
    "#         cur_img = Image.frombytes('RGB', screenshot.size, screenshot.rgb)\n",
    "    \n",
    "#     cur_img_np, is_found = match_live_image(pattern, cur_img)\n",
    "#     cur_img_pil = Image.fromarray(cur_img_np)\n",
    "    \n",
    "#     if is_found:\n",
    "#         is_notfound_cnt = 0\n",
    "#         if is_rotating_right == True:\n",
    "#             is_rotating_right = False\n",
    "#             rotate_right_up()\n",
    "            \n",
    "#         if steer_vert > 0:\n",
    "#             steer_down()\n",
    "#             steer_vert -= 1\n",
    "            \n",
    "#         if weapon_cool_1 <= 0:\n",
    "#             weapon_cool_1 = wc1\n",
    "#             pyautogui.keyDown(\"Num1\")\n",
    "#             time.sleep(0.1)\n",
    "#             pyautogui.keyUp(\"Num1\")\n",
    "            \n",
    "#     elif is_notfound_cnt > 20:\n",
    "#         is_notfound_cnt = 5\n",
    "#         if steer_vert < 2:\n",
    "#             steer_vert += 1\n",
    "#             steer_up()\n",
    "            \n",
    "#         if is_rotating_right == False:\n",
    "#             is_rotating_right = True\n",
    "#             rotate_right_down()\n",
    "#     else:\n",
    "#         is_notfound_cnt += 1\n",
    "        \n",
    "    \n",
    "#     update_image(label, cur_img_pil)\n",
    "#     root.update()\n",
    "#     update_variables(fps+0.1)\n",
    "#     time.sleep(fps)\n",
    "\n",
    "# root.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc5fcc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State declaration\n",
    "# \"\"\"\n",
    "# Target_locked -> 3 value possible -> -1 / 0 / 1\n",
    "# Damage_done -> 2 value possible -> 0 / 1\n",
    "# Movement_horizontal -> 4 value possible -> -1 / 0 / +1 / +2\n",
    "# Movement_vertical -> 3 value possible -> -1 / 0 / 1\n",
    "# Adjust_view -> 3 value possible -> -1 / 0 / 1\n",
    "# Ship_health -> 0% to 100%\n",
    "# Enemy_on_radar -> 0 or 1\n",
    "# Enemy ahead -> 0 or 1\n",
    "# Time_until_you_last_locked_target -> 1sec to 200sec\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99819e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Actions that you can take\n",
    "# \"\"\"\n",
    "# If target_locked state is 1, -> Fire missile by pressing '1'\n",
    "# If there is no enemy-> make movements in the given range  // I don't know how it will move towards enemy but for now it should move randomly searching for them\n",
    "# If and only if there target_locked is negative then try to adjust the view\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2907d8ec-b521-4ff3-8d87-025ad4a319bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rewards\n",
    "# \"\"\"\n",
    "# Reward:\n",
    "# Initialized fire: +4000\n",
    "# Locked_on the enemy: +100\n",
    "# Initating lock_on the enemy: +30\n",
    "# Not_locked on: -20\n",
    "# No_enemy_on_the_radar: -100\n",
    "# If_red_bar_on_the_view: +10\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fccce6a0-2136-4b4f-9dd6-35e1eef746b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchImage(pattern_url, screenshot_url, threshold, lower_range, upper_range, rect_color):\n",
    "    # Target is in gray already preprocessed beforehand\n",
    "    pattern_cv2 = cv2.imread(pattern_url)\n",
    "    tar_gray = cv2.cvtColor(pattern_cv2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "    # Convert to HSV Color Space:\n",
    "    # screenshot_cv2 = np.array(screenshot)[:, :, ::-1].copy()\n",
    "    screenshot_cv2 = cv2.imread(screenshot_url)\n",
    "    hsv_image = cv2.cvtColor(screenshot_cv2, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "    # Define a Color Range:\n",
    "    mask = cv2.inRange(hsv_image, lower_range, upper_range)\n",
    "    \n",
    "    # Apply the Mask:\n",
    "    areas = cv2.bitwise_and(screenshot_cv2, screenshot_cv2, mask=mask)\n",
    "    \n",
    "    # Grayscale to remove noise:\n",
    "    gray_image = cv2.cvtColor(areas, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Template Matching:\n",
    "    result = cv2.matchTemplate(gray_image, tar_gray, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "    is_found = False\n",
    "    loc = np.where(result >= threshold)\n",
    "    \n",
    "    # Now Aiming is complete fire down\n",
    "    if(len(loc[0]) > 0):\n",
    "        is_found = True\n",
    "        pt = (loc[1][0], loc[0][0])  # Take the first match\n",
    "        cv2.rectangle(screenshot_cv2, pt, (pt[0] + pattern_cv2.shape[1], pt[1] + pattern_cv2.shape[0]), rect_color, 2)\n",
    "    \n",
    "    return screenshot_cv2, is_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f47c97d0-04d8-416b-8b63-72debc4534e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # AIM DETECTOR\n",
    "# result_images = []\n",
    "# for i in range(1, 7):\n",
    "#     img, is_present = matchImage(\"./images/aim_complete.png\", \"./Aim_train/\"+str(i)+\".png\", 0.25, np.array([50, 218, 183]),  np.array([175, 255, 255]), (0, 0, 255));\n",
    "#     if is_present:\n",
    "#         result_images.append(img)\n",
    "\n",
    "# for idx, result_image in enumerate(result_images, start=1):\n",
    "#     cv2.imshow(f\"Matching Result {idx}\", result_image)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07523146-6b75-4640-85ad-6f71c8e7cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def checkRadar(pattern_url, screenshot_url, threshold, lower_range, upper_range, rect_color):\n",
    "#     # Target is in gray already preprocessed beforehand\n",
    "#     pattern_cv2 = cv2.imread(pattern_url)\n",
    "#     tar_gray = cv2.cvtColor(pattern_cv2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "#     # Convert to HSV Color Space:\n",
    "#     # screenshot_cv2 = np.array(screenshot)[:, :, ::-1].copy()\n",
    "#     screenshot_cv2 = cv2.imread(screenshot_url)\n",
    "#     height, width, _ = screenshot_cv2.shape\n",
    "    \n",
    "#     # Calculate the cropping dimensions\n",
    "#     crop_top_percentage = 0.4\n",
    "#     crop_left_percentage = 0.25\n",
    "#     crop_top = int(height * crop_top_percentage)\n",
    "#     crop_left = int(width * crop_left_percentage)\n",
    "\n",
    "    \n",
    "#     # Define the cropping percentages\n",
    "#     screenshot_cv2 = screenshot_cv2[:crop_top, :crop_left]    \n",
    "    \n",
    "#     hsv_image = cv2.cvtColor(screenshot_cv2, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "#     # Define a Color Range:\n",
    "#     mask = cv2.inRange(hsv_image, lower_range, upper_range)\n",
    "    \n",
    "#     # Apply the Mask:\n",
    "#     areas = cv2.bitwise_and(screenshot_cv2, screenshot_cv2, mask=mask)\n",
    "    \n",
    "#     # Grayscale to remove noise:\n",
    "#     gray_image = cv2.cvtColor(areas, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "#     # Template Matching:\n",
    "#     result = cv2.matchTemplate(gray_image, tar_gray, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "#     is_found = False\n",
    "#     loc = np.where(result >= threshold)\n",
    "    \n",
    "#     # Now Aiming is complete fire down\n",
    "#     if(len(loc[0]) > 0):\n",
    "#         is_found = True\n",
    "#         pt = (loc[1][0], loc[0][0])  # Take the first match\n",
    "#         cv2.rectangle(screenshot_cv2, pt, (pt[0] + pattern_cv2.shape[1], pt[1] + pattern_cv2.shape[0]), rect_color, 2)\n",
    "    \n",
    "#     return screenshot_cv2, is_found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1801c54c-def3-4587-ab5a-56f93a9fa2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ENEMY \n",
    "# result_images = []\n",
    "# for i in range(1, 7):\n",
    "#     img, is_present = matchImage(\"./images/probable_enemy.png\", \"./Aim_train/\"+str(i)+\".png\", 0.85, np.array([0, 187, 230]),  np.array([0, 255, 255]), (255, 0, 0))\n",
    "#     if is_present:\n",
    "#         result_images.append(img)\n",
    "\n",
    "# for idx, result_image in enumerate(result_images, start=1):\n",
    "#     cv2.imshow(f\"Matching Result {idx}\", result_image)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1582f0c2-5875-44d3-91cf-515599991391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ENEMY ON RADAR\n",
    "# result_images = []\n",
    "# for i in range(1, 7):\n",
    "#     img, is_present = checkRadar(\"./images/radar_tracker.png\", \"./Aim_train/\"+str(i)+\".png\", 0.17, np.array([0, 187, 230]),  np.array([0, 255, 255]), (0, 255, 0))\n",
    "#     if is_present:\n",
    "#         result_images.append(img)\n",
    "\n",
    "# for idx, result_image in enumerate(result_images, start=1):\n",
    "#     cv2.imshow(f\"Matching Result {idx}\", result_image)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369909e7-9442-4488-a57c-a83fdda32a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Collision detection\n",
    "\n",
    "# result_images = []\n",
    "# for i in range(1, 5):\n",
    "#     img, is_present = matchImage(\"./images/collide_tracker.png\", \"./Collide_train/\"+str(i)+\".png\", 0.50, np.array([0, 0, 145]),  np.array([161, 43, 255]), (0, 255, 0))\n",
    "#     if is_present:\n",
    "#         result_images.append(img)\n",
    "\n",
    "# for idx, result_image in enumerate(result_images, start=1):\n",
    "#     cv2.imshow(f\"Matching Result {idx}\", result_image)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75072870-6586-4326-985a-04e71594fdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "class YourEnvironment(gym.Env):\n",
    "    def __init__(self):\n",
    "        # Initialization of your environment parameters\n",
    "        self.action_space = gym.spaces.Discrete(4)  # Assuming 4 possible actions\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(11,), dtype=float)  # Assuming 10 states\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset the environment to the initial state\n",
    "        self.target_locked = 0 # Done\n",
    "        self.target_locked_time = 0 \n",
    "        self.damage_done = 0 # Can be Done\n",
    "        self.movement_horizontal = 0 # Can be Done\n",
    "        self.movement_vertical = 0 # Can be Done\n",
    "        self.adjust_view = 0 # Random\n",
    "        self.ship_health_percentage = 100.0\n",
    "        self.time_until_last_locked_target = 0 # Can be Done\n",
    "        self.enemy_on_radar = 0 # Done\n",
    "        self.red_bar_on_view = 0 # Done\n",
    "        self.reload_1 = 0\n",
    "        self.current_screenshot = None\n",
    "        self.continuous_lockon_enemy = 0\n",
    "        self.collision_time = 0\n",
    "        self.reward = 0\n",
    "\n",
    "        return self.get_state()\n",
    "\n",
    "    def step(self, action):\n",
    "        # Take a step in the environment based on the agent's action\n",
    "        self.update_states(action)\n",
    "        reward = self.calculate_reward()  # Implement your reward logic\n",
    "        done = self.check_done()  # Implement your termination logic\n",
    "        arr = ['none', 'fire', 'move', 'view'] \n",
    "        print(f\"Action: {arr[action]}, Reward: {reward}, Done: {done}, Idle Time: {self.time_until_last_locked_target}\")\n",
    "\n",
    "        return self.get_state(), reward, done, {}\n",
    "\n",
    "    def update_states(self, action):\n",
    "        # Update states based on the agent's action\n",
    "        self.current_screenshot = self.update_screenshot()\n",
    "\n",
    "        # Check if target is locked:\n",
    "        img, is_present = self.matchImage(\"./images/aim_complete.png\", 0.3, np.array([50, 218, 183]),  np.array([175, 255, 255]), (0, 0, 255))\n",
    "        self.target_locked = is_present\n",
    "        if is_present == False:\n",
    "            self.target_locked_time = 0\n",
    "        else:\n",
    "            self.target_locked_time += 1\n",
    "        \n",
    "        # Check if enemy is on radar:\n",
    "        img, is_present = self.checkRadar(\"./images/radar_tracker.png\", 0.17, np.array([0, 187, 230]),  np.array([0, 255, 255]), (0, 255, 0))\n",
    "        self.enemy_on_radar = is_present\n",
    "        \n",
    "        # Check if red bar is present:\n",
    "        img, is_present = self.matchImage(\"./images/probable_enemy.png\", 0.85, np.array([0, 187, 230]),  np.array([0, 255, 255]), (255, 0, 0))\n",
    "        self.red_bar_on_view = is_present\n",
    "        \n",
    "        if is_present == 1:\n",
    "            self.continuous_lockon_enemy += 1;\n",
    "        else:\n",
    "            self.continuous_lockon_enemy = 0;\n",
    "\n",
    "        \n",
    "        img, is_present = self.matchImage(\"./images/collide_tracker.png\", 0.50, np.array([0, 0, 145]), np.array([161, 43, 255]), (0, 255, 0))\n",
    "\n",
    "        if is_present == 1:\n",
    "            self.collision_time += 1;\n",
    "        else:\n",
    "            self.collision = 0;\n",
    "        \n",
    "        if self.target_locked != 1:\n",
    "            self.time_until_last_locked_target += 1\n",
    "            self.reload_1 += 1\n",
    "\n",
    "            \n",
    "        if action == 0:  # Action: Do nothing\n",
    "            self.reward = 0\n",
    "            pass\n",
    "        elif action == 1: # Action: fire\n",
    "            if self.target_locked == 1 and self.reload_1 > 10:\n",
    "                self.time_until_last_locked_target = 0\n",
    "                self.reload_1 = 0\n",
    "                self.fire_key_1()\n",
    "                self.damage_done = 1\n",
    "                self.reward = 30\n",
    "        elif action == 2:  # Action: Random movements\n",
    "            if self.target_locked != 1:\n",
    "                self.reward = 0\n",
    "                self.do_random_movement()\n",
    "        elif action == 3:  # Action: Adjust view\n",
    "            if self.target_locked != 1:\n",
    "                self.reward = 0\n",
    "                self.do_random_viewing()\n",
    "\n",
    "    def get_state(self):\n",
    "        # Return the current state as a vector\n",
    "        return [\n",
    "            self.target_locked,\n",
    "            self.damage_done,\n",
    "            self.movement_horizontal,\n",
    "            self.movement_vertical,\n",
    "            self.adjust_view,\n",
    "            self.ship_health_percentage,\n",
    "            self.time_until_last_locked_target,\n",
    "            self.enemy_on_radar,\n",
    "            self.red_bar_on_view,\n",
    "            self.continuous_lockon_enemy,\n",
    "            self.collision_time\n",
    "        ]\n",
    "\n",
    "    def calculate_reward(self):\n",
    "        # Reward initialization\n",
    "        reward = self.reward\n",
    "    \n",
    "        # Check if fire is initialized\n",
    "        if self.target_locked == 1:\n",
    "            reward += 5*(self.target_locked_time)\n",
    "            reward += 20\n",
    "    \n",
    "        # Check if the enemy is on radar\n",
    "        if self.enemy_on_radar == 1:\n",
    "            reward += 10\n",
    "            \n",
    "        # Check if not locked on\n",
    "        if self.target_locked == 0:\n",
    "            reward -= 11\n",
    "    \n",
    "        # Check if no enemy on the radar\n",
    "        if self.enemy_on_radar == 0:\n",
    "            reward -= 2*(self.time_until_last_locked_target)\n",
    "    \n",
    "        # Check if red bar on the view\n",
    "        if self.red_bar_on_view == 1:\n",
    "            reward += 1*(self.continuous_lockon_enemy)\n",
    "\n",
    "        if self.collision_time == 0:\n",
    "            reward += 1\n",
    "        elif self.collision_time > 1:\n",
    "            reward -= 5\n",
    "        elif self.collision_time > 3:\n",
    "            reward -= 20\n",
    "    \n",
    "        return reward\n",
    "\n",
    "\n",
    "    def check_done(self):\n",
    "        # Implement your termination condition\n",
    "        if self.time_until_last_locked_target > 80:\n",
    "            self.reset()\n",
    "            return True  # Environment terminates when time exceeds 80\n",
    "        else:\n",
    "            return False  # Environment continues if time is less than or equal to 80\n",
    "        \n",
    "    def update_screenshot(self):\n",
    "        region = {'left': 0, 'top': 0, 'width': 950, 'height': 566}\n",
    "        with mss() as sct:\n",
    "            screenshot = sct.grab(region)\n",
    "            cur_img = Image.frombytes('RGB', screenshot.size, screenshot.rgb)\n",
    "            screenshot_cv2 = cv2.cvtColor(np.array(cur_img), cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "        return screenshot_cv2\n",
    "\n",
    "    def fire_key_1(self):\n",
    "        pyautogui.keyDown(\"Num1\")\n",
    "        time.sleep(0.1)\n",
    "        pyautogui.keyUp(\"Num1\")\n",
    "\n",
    "    def move_left(self):\n",
    "        pyautogui.keyDown(\"A\")\n",
    "        time.sleep(0.2)\n",
    "        pyautogui.keyUp(\"A\")\n",
    "\n",
    "    def move_right(self):\n",
    "        pyautogui.keyDown(\"D\")\n",
    "        time.sleep(0.2)\n",
    "        pyautogui.keyUp(\"D\")\n",
    "\n",
    "    def steer_up(self):\n",
    "        pyautogui.keyDown(\"W\")\n",
    "        time.sleep(0.1)\n",
    "        pyautogui.keyUp(\"W\")\n",
    "\n",
    "    def steer_down(self):\n",
    "        pyautogui.keyDown(\"S\")\n",
    "        time.sleep(0.1)\n",
    "        pyautogui.keyUp(\"S\")\n",
    "\n",
    "    def view_right(self, t):\n",
    "        pyautogui.keyDown(\"L\")\n",
    "        time.sleep(t)\n",
    "        pyautogui.keyUp(\"L\")\n",
    "\n",
    "    def view_left(self, t):\n",
    "        pyautogui.keyDown(\"J\")\n",
    "        time.sleep(t)\n",
    "        pyautogui.keyUp(\"J\")\n",
    "    \n",
    "    def do_random_movement(self):\n",
    "        horizontal_movement = random.choice([-1, 0, 1])\n",
    "        vertical_movement = random.choice([-1, 0, 1])\n",
    "\n",
    "        if horizontal_movement == -1:\n",
    "            self.move_left()\n",
    "        elif horizontal_movement == 1:\n",
    "            self.move_right()\n",
    "\n",
    "        if vertical_movement == -1:\n",
    "            self.steer_down()\n",
    "            self.vertical_movement = max(self.movement_vertical-1, -1)\n",
    "        elif vertical_movement == 1:\n",
    "            self.steer_up()\n",
    "            self.vertical_movement = min(self.movement_vertical+1, 2)\n",
    "\n",
    "    def do_random_viewing(self):\n",
    "        view_direction = random.choice([-1, 1])\n",
    "        if view_direction == -1:\n",
    "            self.view_left(0.2)\n",
    "        elif view_direction == 1:\n",
    "            self.view_right(0.2)\n",
    "\n",
    "    def checkRadar(self, pattern_url, threshold, lower_range, upper_range, rect_color):\n",
    "        pattern_cv2 = cv2.imread(pattern_url)\n",
    "        tar_gray = cv2.cvtColor(pattern_cv2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "        # Convert to HSV Color Space:\n",
    "        # screenshot_cv2 = np.array(screenshot)[:, :, ::-1].copy()\n",
    "        screenshot_cv2 = self.current_screenshot\n",
    "        height, width, _ = screenshot_cv2.shape\n",
    "        \n",
    "        # Calculate the cropping dimensions\n",
    "        crop_top_percentage = 0.4\n",
    "        crop_left_percentage = 0.25\n",
    "        crop_top = int(height * crop_top_percentage)\n",
    "        crop_left = int(width * crop_left_percentage)\n",
    "    \n",
    "        \n",
    "        # Define the cropping percentages\n",
    "        screenshot_cv2 = screenshot_cv2[:crop_top, :crop_left]    \n",
    "        \n",
    "        hsv_image = cv2.cvtColor(screenshot_cv2, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    \n",
    "        # Define a Color Range:\n",
    "        mask = cv2.inRange(hsv_image, lower_range, upper_range)\n",
    "        \n",
    "        # Apply the Mask:\n",
    "        areas = cv2.bitwise_and(screenshot_cv2, screenshot_cv2, mask=mask)\n",
    "        \n",
    "        # Grayscale to remove noise:\n",
    "        gray_image = cv2.cvtColor(areas, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Template Matching:\n",
    "        result = cv2.matchTemplate(gray_image, tar_gray, cv2.TM_CCOEFF_NORMED)\n",
    "    \n",
    "        is_found = False\n",
    "        loc = np.where(result >= threshold)\n",
    "        \n",
    "        # Now Aiming is complete fire down\n",
    "        if(len(loc[0]) > 0):\n",
    "            is_found = True\n",
    "            pt = (loc[1][0], loc[0][0])  # Take the first match\n",
    "            cv2.rectangle(screenshot_cv2, pt, (pt[0] + pattern_cv2.shape[1], pt[1] + pattern_cv2.shape[0]), rect_color, 2)\n",
    "        \n",
    "        return screenshot_cv2, is_found\n",
    "\n",
    "    def matchImage(self, pattern_url, threshold, lower_range, upper_range, rect_color):\n",
    "        pattern_cv2 = cv2.imread(pattern_url)\n",
    "        tar_gray = cv2.cvtColor(pattern_cv2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "        # Convert to HSV Color Space:\n",
    "        screenshot_cv2 = self.current_screenshot\n",
    "        hsv_image = cv2.cvtColor(screenshot_cv2, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    \n",
    "        # Define a Color Range:\n",
    "        mask = cv2.inRange(hsv_image, lower_range, upper_range)\n",
    "        \n",
    "        # Apply the Mask:\n",
    "        areas = cv2.bitwise_and(screenshot_cv2, screenshot_cv2, mask=mask)\n",
    "        \n",
    "        # Grayscale to remove noise:\n",
    "        gray_image = cv2.cvtColor(areas, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Template Matching:\n",
    "        result = cv2.matchTemplate(gray_image, tar_gray, cv2.TM_CCOEFF_NORMED)\n",
    "    \n",
    "        is_found = False\n",
    "        loc = np.where(result >= threshold)\n",
    "        \n",
    "        # Now Aiming is complete fire down\n",
    "        if(len(loc[0]) > 0):\n",
    "            is_found = True\n",
    "            pt = (loc[1][0], loc[0][0])  # Take the first match\n",
    "            cv2.rectangle(screenshot_cv2, pt, (pt[0] + pattern_cv2.shape[1], pt[1] + pattern_cv2.shape[0]), rect_color, 2)\n",
    "        \n",
    "        return screenshot_cv2, is_found\n",
    "\n",
    "class EpisodeTerminationCallback(BaseCallback):\n",
    "    def __init__(self, episode_limit, verbose=1):\n",
    "        super(EpisodeTerminationCallback, self).__init__(verbose)\n",
    "        self.episode_limit = episode_limit\n",
    "        self.episode_count = 0\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        self.episode_count += 1\n",
    "        if self.episode_count >= self.episode_limit:\n",
    "            self.episode_count = 0\n",
    "            print(f\"Terminating training after {self.episode_limit} episodes.\")\n",
    "            return False  # Return False to stop training\n",
    "        return True  # Return True to continue training\n",
    "\n",
    "env = YourEnvironment()\n",
    "model = PPO(\"MlpPolicy\", env, verbose=0)\n",
    "\n",
    "\n",
    "# # Train the model\n",
    "# model.learn(total_timesteps=48000, callback=episode_limit_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fe9d87d-77e3-4c21-87fd-2ac23aa69585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# episode_limit_callback = EpisodeTerminationCallback(10)\n",
    "# model = PPO.load(\"trained_model.zip\", env, verbose=0)\n",
    "# model.learn(total_timesteps=48000, callback=episode_limit_callback)\n",
    "# model.save(\"trained_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b3684b3-134b-4a8b-97ec-4fc8a9c08507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_iteration():\n",
    "    print(\"First iteration starting in 5 seconds.\")\n",
    "    time.sleep(5)\n",
    "    episode_limit_callback = EpisodeTerminationCallback(150)\n",
    "    model.learn(total_timesteps=48000, callback=episode_limit_callback)\n",
    "    model.save(\"trained_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "878405b4-1e07-4e87-9087-f534725c1be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_train(max_itr):\n",
    "    itr = 0\n",
    "    while itr < max_itr:        \n",
    "        if os.path.exists(\"trained_model.zip\"):\n",
    "            print(\"File found, starting model training on the base of the saved model.\")\n",
    "            env = YourEnvironment()\n",
    "            model = PPO.load(\"trained_model.zip\", env, verbose=0)\n",
    "            episode_limit_callback = EpisodeTerminationCallback(150)\n",
    "            model.learn(total_timesteps=48000, callback=episode_limit_callback)\n",
    "            model.save(\"trained_model.zip\")\n",
    "        else:\n",
    "            print(\"File not found, starting first iteration\")\n",
    "            first_iteration();\n",
    "        \n",
    "        itr += 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "099cbc74-83ab-4400-bda4-d9dc32ee7f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found, starting first iteration\n",
      "First iteration starting in 5 seconds.\n",
      "Action: view, Reward: -12, Done: False, Idle Time: 1\n",
      "Action: none, Reward: -14, Done: False, Idle Time: 2\n",
      "Action: view, Reward: -16, Done: False, Idle Time: 3\n",
      "Action: none, Reward: -18, Done: False, Idle Time: 4\n",
      "Action: none, Reward: -20, Done: False, Idle Time: 5\n",
      "Action: move, Reward: -22, Done: False, Idle Time: 6\n",
      "Action: view, Reward: -24, Done: False, Idle Time: 7\n",
      "Action: fire, Reward: -26, Done: False, Idle Time: 8\n",
      "Action: fire, Reward: -28, Done: False, Idle Time: 9\n",
      "Action: view, Reward: -30, Done: False, Idle Time: 10\n",
      "Terminating training after 10 episodes.\n",
      "File found, starting model training on the base of the saved model.\n",
      "Action: fire, Reward: -12, Done: False, Idle Time: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: move, Reward: -14, Done: False, Idle Time: 2\n",
      "Action: move, Reward: -16, Done: False, Idle Time: 3\n",
      "Action: fire, Reward: -18, Done: False, Idle Time: 4\n",
      "Action: none, Reward: -20, Done: False, Idle Time: 5\n",
      "Action: none, Reward: -22, Done: False, Idle Time: 6\n",
      "Action: view, Reward: -24, Done: False, Idle Time: 7\n",
      "Action: fire, Reward: -26, Done: False, Idle Time: 8\n",
      "Action: none, Reward: -28, Done: False, Idle Time: 9\n",
      "Action: move, Reward: -30, Done: False, Idle Time: 10\n",
      "Action: move, Reward: -32, Done: False, Idle Time: 11\n",
      "Action: view, Reward: -34, Done: False, Idle Time: 12\n",
      "Action: fire, Reward: -36, Done: False, Idle Time: 13\n",
      "Action: fire, Reward: -38, Done: False, Idle Time: 14\n",
      "Action: none, Reward: -40, Done: False, Idle Time: 15\n",
      "Action: none, Reward: -42, Done: False, Idle Time: 16\n",
      "Action: fire, Reward: -44, Done: False, Idle Time: 17\n",
      "Action: view, Reward: -46, Done: False, Idle Time: 18\n",
      "Action: move, Reward: -48, Done: False, Idle Time: 19\n",
      "Action: move, Reward: -50, Done: False, Idle Time: 20\n",
      "Action: move, Reward: -52, Done: False, Idle Time: 21\n",
      "Action: fire, Reward: -54, Done: False, Idle Time: 22\n",
      "Action: view, Reward: -56, Done: False, Idle Time: 23\n",
      "Action: none, Reward: -58, Done: False, Idle Time: 24\n",
      "Action: view, Reward: -60, Done: False, Idle Time: 25\n",
      "Action: view, Reward: -62, Done: False, Idle Time: 26\n",
      "Action: none, Reward: -64, Done: False, Idle Time: 27\n",
      "Action: fire, Reward: -66, Done: False, Idle Time: 28\n",
      "Action: none, Reward: -68, Done: False, Idle Time: 29\n",
      "Action: view, Reward: -70, Done: False, Idle Time: 30\n",
      "Action: view, Reward: -72, Done: False, Idle Time: 31\n",
      "Action: none, Reward: -74, Done: False, Idle Time: 32\n",
      "Action: none, Reward: -76, Done: False, Idle Time: 33\n",
      "Action: move, Reward: -78, Done: False, Idle Time: 34\n",
      "Action: view, Reward: -80, Done: False, Idle Time: 35\n",
      "Action: move, Reward: -82, Done: False, Idle Time: 36\n",
      "Action: move, Reward: -84, Done: False, Idle Time: 37\n",
      "Action: none, Reward: -86, Done: False, Idle Time: 38\n",
      "Action: fire, Reward: -88, Done: False, Idle Time: 39\n",
      "Action: move, Reward: -90, Done: False, Idle Time: 40\n",
      "Action: fire, Reward: -92, Done: False, Idle Time: 41\n",
      "Action: view, Reward: -94, Done: False, Idle Time: 42\n",
      "Action: fire, Reward: -96, Done: False, Idle Time: 43\n",
      "Action: none, Reward: -98, Done: False, Idle Time: 44\n",
      "Action: none, Reward: -100, Done: False, Idle Time: 45\n",
      "Action: view, Reward: -102, Done: False, Idle Time: 46\n",
      "Action: move, Reward: -104, Done: False, Idle Time: 47\n",
      "Action: none, Reward: -106, Done: False, Idle Time: 48\n",
      "Action: fire, Reward: -108, Done: False, Idle Time: 49\n",
      "Action: fire, Reward: -110, Done: False, Idle Time: 50\n",
      "Action: none, Reward: -112, Done: False, Idle Time: 51\n",
      "Action: none, Reward: -114, Done: False, Idle Time: 52\n",
      "Action: none, Reward: -116, Done: False, Idle Time: 53\n",
      "Action: move, Reward: -118, Done: False, Idle Time: 54\n",
      "Action: none, Reward: -120, Done: False, Idle Time: 55\n",
      "Action: none, Reward: -122, Done: False, Idle Time: 56\n",
      "Action: none, Reward: -124, Done: False, Idle Time: 57\n",
      "Action: move, Reward: -126, Done: False, Idle Time: 58\n",
      "Action: none, Reward: -128, Done: False, Idle Time: 59\n",
      "Action: view, Reward: -130, Done: False, Idle Time: 60\n",
      "Action: fire, Reward: -132, Done: False, Idle Time: 61\n",
      "Action: move, Reward: -134, Done: False, Idle Time: 62\n",
      "Action: fire, Reward: -136, Done: False, Idle Time: 63\n",
      "Action: fire, Reward: -138, Done: False, Idle Time: 64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mstart_train\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 9\u001b[0m, in \u001b[0;36mstart_train\u001b[1;34m(max_itr)\u001b[0m\n\u001b[0;32m      7\u001b[0m     model \u001b[38;5;241m=\u001b[39m PPO\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained_model.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      8\u001b[0m     episode_limit_callback \u001b[38;5;241m=\u001b[39m EpisodeTerminationCallback(\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m48000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepisode_limit_callback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained_model.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:300\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 300\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:195\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;66;03m# Otherwise, clip the actions to avoid out of bound error\u001b[39;00m\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;66;03m# as we are sampling from an unbounded Gaussian distribution\u001b[39;00m\n\u001b[0;32m    193\u001b[0m         clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[1;32m--> 195\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[1;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shimmy\\openai_gym_compatibility.py:251\u001b[0m, in \u001b[0;36mGymV21CompatibilityV0.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: ActType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[Any, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[0;32m    243\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m        (observation, reward, terminated, truncated, info)\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m     obs, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgym_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender()\n",
      "Cell \u001b[1;32mIn[19], line 34\u001b[0m, in \u001b[0;36mYourEnvironment.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Take a step in the environment based on the agent's action\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_reward()  \u001b[38;5;66;03m# Implement your reward logic\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_done()  \u001b[38;5;66;03m# Implement your termination logic\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[19], line 97\u001b[0m, in \u001b[0;36mYourEnvironment.update_states\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_locked \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_random_viewing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 223\u001b[0m, in \u001b[0;36mYourEnvironment.do_random_viewing\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mview_left(\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m view_direction \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 223\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview_right\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 194\u001b[0m, in \u001b[0;36mYourEnvironment.view_right\u001b[1;34m(self, t)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mview_right\u001b[39m(\u001b[38;5;28mself\u001b[39m, t):\n\u001b[0;32m    193\u001b[0m     pyautogui\u001b[38;5;241m.\u001b[39mkeyDown(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 194\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(t)\n\u001b[0;32m    195\u001b[0m     pyautogui\u001b[38;5;241m.\u001b[39mkeyUp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_train(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea64eab6-7f60-46af-ada4-909cd5ca76a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
