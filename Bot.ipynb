{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33faa8e5-a6ac-456e-ba45-806e8c6ea4d4",
   "metadata": {},
   "source": [
    "# JDSAWLDWLJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a96985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mss import mss # screen grabber\n",
    "import pyautogui\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk # screen replay\n",
    "import time # For delay\n",
    "import cv2\n",
    "import random \n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ecd770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get screen region co-ordinate manually\n",
    "# import pyautogui\n",
    "# import time\n",
    "\n",
    "# # Get mouse position\n",
    "# while True:\n",
    "#     brk = input(\"Press Enter to get position or any other key to break: \")\n",
    "#     if(brk):\n",
    "#         break;\n",
    "#     x, y = pyautogui.position()\n",
    "#     print(f\"Current mouse position: x={x}, y={y}\")\n",
    "#     time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18f0dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check screen region \n",
    "# from mss import mss\n",
    "# from PIL import Image\n",
    "# # x=81, y=32\n",
    "# # x=1343, y=744\n",
    "# # Get Screenshot\n",
    "# region = {'left': 80, 'top': 32, 'width': 950, 'height': 531}\n",
    "# with mss() as sct:\n",
    "#     screenshot = sct.grab(region)\n",
    "#     img = Image.frombytes('RGB', screenshot.size, screenshot.rgb)\n",
    "#     img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a290ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tutorial detection\n",
    "# import time\n",
    "# import mss\n",
    "# import pyautogui\n",
    "\n",
    "# # aim_detect = pyautogui.locateOnScreen(\"./images/aim_complete.png\", confidence=0.5)\n",
    "# # print(aim_detect)\n",
    "\n",
    "# aim_detect = pyautogui.locateCenterOnScreen(\"./images/aim_complete.png\", confidence=0.6)\n",
    "# pyautogui.moveTo(aim_detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1df3c659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Color range selector code\n",
    "# # https://stackoverflow.com/questions/10948589/choosing-the-correct-upper-and-lower-hsv-boundaries-for-color-detection-withcv\n",
    "\n",
    "# def nothing(x):\n",
    "#     pass\n",
    "\n",
    "# # Load image\n",
    "# image = cv2.imread(\"./images/game_over_screen.png\")\n",
    "\n",
    "# # Create a window\n",
    "# cv2.namedWindow('image')\n",
    "\n",
    "# # Create trackbars for color change\n",
    "# # Hue is from 0-179 for Opencv\n",
    "# cv2.createTrackbar('HMin', 'image', 0, 179, nothing)\n",
    "# cv2.createTrackbar('SMin', 'image', 0, 255, nothing)\n",
    "# cv2.createTrackbar('VMin', 'image', 0, 255, nothing)\n",
    "# cv2.createTrackbar('HMax', 'image', 0, 179, nothing)\n",
    "# cv2.createTrackbar('SMax', 'image', 0, 255, nothing)\n",
    "# cv2.createTrackbar('VMax', 'image', 0, 255, nothing)\n",
    "\n",
    "# # Set default value for Max HSV trackbars\n",
    "# cv2.setTrackbarPos('HMax', 'image', 179)\n",
    "# cv2.setTrackbarPos('SMax', 'image', 255)\n",
    "# cv2.setTrackbarPos('VMax', 'image', 255)\n",
    "\n",
    "# # Initialize HSV min/max values\n",
    "# hMin = sMin = vMin = hMax = sMax = vMax = 0\n",
    "# phMin = psMin = pvMin = phMax = psMax = pvMax = 0\n",
    "\n",
    "# while(1):\n",
    "#     # Get current positions of all trackbars\n",
    "#     hMin = cv2.getTrackbarPos('HMin', 'image')\n",
    "#     sMin = cv2.getTrackbarPos('SMin', 'image')\n",
    "#     vMin = cv2.getTrackbarPos('VMin', 'image')\n",
    "#     hMax = cv2.getTrackbarPos('HMax', 'image')\n",
    "#     sMax = cv2.getTrackbarPos('SMax', 'image')\n",
    "#     vMax = cv2.getTrackbarPos('VMax', 'image')\n",
    "\n",
    "#     # Set minimum and maximum HSV values to display\n",
    "#     lower = np.array([hMin, sMin, vMin])\n",
    "#     upper = np.array([hMax, sMax, vMax])\n",
    "\n",
    "#     # Convert to HSV format and color threshold\n",
    "#     hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "#     mask = cv2.inRange(hsv, lower, upper)\n",
    "#     result = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "#     # Print if there is a change in HSV value\n",
    "#     if((phMin != hMin) | (psMin != sMin) | (pvMin != vMin) | (phMax != hMax) | (psMax != sMax) | (pvMax != vMax) ):\n",
    "#         print(\"(hMin = %d , sMin = %d, vMin = %d), (hMax = %d , sMax = %d, vMax = %d)\" % (hMin , sMin , vMin, hMax, sMax , vMax))\n",
    "#         phMin = hMin\n",
    "#         psMin = sMin\n",
    "#         pvMin = vMin\n",
    "#         phMax = hMax\n",
    "#         psMax = sMax\n",
    "#         pvMax = vMax\n",
    "\n",
    "#     # Display result image\n",
    "#     cv2.imshow('image', result)\n",
    "#     if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffc92fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pattern matcher for aim circle\n",
    "\n",
    "# def match_image(pattern_url, image_url):\n",
    "#     tar = cv2.imread(pattern_url)\n",
    "#     tar_gray = cv2.cvtColor(tar, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "#     # Convert to HSV Color Space:\n",
    "#     image = cv2.imread(image_url)\n",
    "#     hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "#     # Define a Green Color Range:\n",
    "#     lower_green = np.array([50, 218, 183])  # Adjust these values based on your specific shade of green\n",
    "#     upper_green = np.array([175, 255, 255])\n",
    "#     mask = cv2.inRange(hsv_image, lower_green, upper_green)\n",
    "\n",
    "#     # Apply the Mask:\n",
    "#     green_areas = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "#     # Grayscale and blur to remove noise:\n",
    "#     gray_image = cv2.cvtColor(green_areas, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     # Template Matching:\n",
    "#     result = cv2.matchTemplate(gray_image, tar_gray, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "\n",
    "#     threshold = 0.3\n",
    "#     loc = np.where(result >= threshold)\n",
    "\n",
    "#     for pt in zip(*loc[::-1]):\n",
    "#         cv2.rectangle(image, pt, (pt[0] + tar.shape[1], pt[1] + tar.shape[0]), (0, 0, 255), 2)\n",
    "    \n",
    "#     return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7ca9b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display detections\n",
    "# result_images = []\n",
    "# for i in range(1, 7):\n",
    "    # img = match_image(\"./images/aim_complete.png\", \"./Aim_train/\"+str(i)+\".png\")\n",
    "#     result_images.append(img)\n",
    "\n",
    "# for idx, result_image in enumerate(result_images, start=1):\n",
    "#     cv2.imshow(f\"Matching Result {idx}\", result_image)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f0ddeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Movements control:\n",
    "# steer_up_key = \"W\"\n",
    "# steer_down_key = \"S\"\n",
    "# steer_right_key = \"R\"\n",
    "# steer_left_key = \"L\"\n",
    "\n",
    "# view_up_key = \"I\"\n",
    "# view_down_key = \"K\"\n",
    "# view_left_key = \"J\"\n",
    "# view_right_key = \"L\"\n",
    "\n",
    "# def rotate_right_down():\n",
    "#     pyautogui.keyDown(\"L\")\n",
    "    \n",
    "# def rotate_right_up():\n",
    "#     pyautogui.keyUp(\"L\")\n",
    "    \n",
    "# def steer_up():\n",
    "#     pyautogui.keyDown(\"W\")\n",
    "#     time.sleep(0.1)\n",
    "#     pyautogui.keyUp(\"W\")\n",
    "\n",
    "# def steer_down():\n",
    "#     pyautogui.keyDown(\"S\")\n",
    "#     time.sleep(0.1)\n",
    "#     pyautogui.keyUp(\"S\")\n",
    "\n",
    "# # Fire keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "374676b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pattern matcher for aim circle\n",
    "# def match_live_image(pattern, image_live):\n",
    "#     # Target is in gray already preprocessed beforehand\n",
    "#     pattern_cv2 = np.array(pattern)[:, :, ::-1].copy()\n",
    "#     tar_gray = cv2.cvtColor(pattern_cv2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "#     # Convert to HSV Color Space:\n",
    "#     image_live_cv2 = np.array(image_live)[:, :, ::-1].copy()\n",
    "#     hsv_image = cv2.cvtColor(image_live_cv2, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "#     # Define a Green Color Range:\n",
    "#     lower_green = np.array([50, 218, 183])  # Adjust these values based on your specific shade of green\n",
    "#     upper_green = np.array([175, 255, 255])\n",
    "#     mask = cv2.inRange(hsv_image, lower_green, upper_green)\n",
    "#     # Apply the Mask:\n",
    "#     green_areas = cv2.bitwise_and(image_live_cv2, image_live_cv2, mask=mask)\n",
    "    \n",
    "#     # Grayscale and blur to remove noise:\n",
    "#     gray_image = cv2.cvtColor(green_areas, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "#     # Template Matching:\n",
    "#     result = cv2.matchTemplate(gray_image, tar_gray, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "\n",
    "#     threshold = 0.27\n",
    "#     is_found = False\n",
    "#     loc = np.where(result >= threshold)\n",
    "    \n",
    "#     # Now Aiming is complete fire down\n",
    "#     if(len(loc[0]) > 0):\n",
    "#         is_found = True\n",
    "    \n",
    "    \n",
    "#     for pt in zip(*loc[::-1]):\n",
    "#         cv2.rectangle(image_live_cv2, pt, (pt[0] + pattern_cv2.shape[1], pt[1] + pattern_cv2.shape[0]), (0, 0, 255), 2)\n",
    "    \n",
    "#     image_live_cv2 = image_live_cv2[:, :, ::-1].copy()\n",
    "#     return image_live_cv2, is_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5505318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Real-time player\n",
    "# # x=81, y=32\n",
    "# # x=1343, y=744\n",
    "# region = {'left': 80, 'top': 32, 'width': 950, 'height': 531}\n",
    "\n",
    "# # Create a tkinter window\n",
    "# root = tk.Tk()\n",
    "# root.title(\"Replay\")\n",
    "# initial_x = 81\n",
    "# initial_y = 536\n",
    "# root.geometry(f\"+{initial_x}+{initial_y}\")\n",
    "\n",
    "# # Why need label??\n",
    "# # Create a label to display the image in the tkinter window\n",
    "# label = tk.Label(root)\n",
    "# label.pack()\n",
    "\n",
    "# def update_image(label, img):\n",
    "#     image_tk = ImageTk.PhotoImage(img)\n",
    "#     label.configure(image=image_tk)\n",
    "#     label.image = image_tk\n",
    "\n",
    "# # Initialize\n",
    "# keep_playing = True;\n",
    "# def exit_loop(event):            \n",
    "#     global keep_playing\n",
    "#     keep_playing = False\n",
    "\n",
    "# root.bind('<`>', exit_loop)\n",
    "\n",
    "# # VARIABLES\n",
    "# pattern = Image.open(\"./images/aim_complete.png\")\n",
    "# fps = 0\n",
    "# wc1 = 8\n",
    "# weapon_cool_1 = wc1\n",
    "# is_notfound_cnt = 0\n",
    "# is_rotating_right = False\n",
    "# steer_vert = 0\n",
    "\n",
    "# def update_variables(time):\n",
    "#     global weapon_cool_1\n",
    "#     weapon_cool_1 = max(0, weapon_cool_1 - time)\n",
    "\n",
    "# # Image as video\n",
    "# while keep_playing:\n",
    "#     with mss() as sct:\n",
    "#         screenshot = sct.grab(region)\n",
    "#         cur_img = Image.frombytes('RGB', screenshot.size, screenshot.rgb)\n",
    "    \n",
    "#     cur_img_np, is_found = match_live_image(pattern, cur_img)\n",
    "#     cur_img_pil = Image.fromarray(cur_img_np)\n",
    "    \n",
    "#     if is_found:\n",
    "#         is_notfound_cnt = 0\n",
    "#         if is_rotating_right == True:\n",
    "#             is_rotating_right = False\n",
    "#             rotate_right_up()\n",
    "            \n",
    "#         if steer_vert > 0:\n",
    "#             steer_down()\n",
    "#             steer_vert -= 1\n",
    "            \n",
    "#         if weapon_cool_1 <= 0:\n",
    "#             weapon_cool_1 = wc1\n",
    "#             pyautogui.keyDown(\"Num1\")\n",
    "#             time.sleep(0.1)\n",
    "#             pyautogui.keyUp(\"Num1\")\n",
    "            \n",
    "#     elif is_notfound_cnt > 20:\n",
    "#         is_notfound_cnt = 5\n",
    "#         if steer_vert < 2:\n",
    "#             steer_vert += 1\n",
    "#             steer_up()\n",
    "            \n",
    "#         if is_rotating_right == False:\n",
    "#             is_rotating_right = True\n",
    "#             rotate_right_down()\n",
    "#     else:\n",
    "#         is_notfound_cnt += 1\n",
    "        \n",
    "    \n",
    "#     update_image(label, cur_img_pil)\n",
    "#     root.update()\n",
    "#     update_variables(fps+0.1)\n",
    "#     time.sleep(fps)\n",
    "\n",
    "# root.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc5fcc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State declaration\n",
    "# \"\"\"\n",
    "# Target_locked -> 3 value possible -> -1 / 0 / 1\n",
    "# Damage_done -> 2 value possible -> 0 / 1\n",
    "# Movement_horizontal -> 4 value possible -> -1 / 0 / +1 / +2\n",
    "# Movement_vertical -> 3 value possible -> -1 / 0 / 1\n",
    "# Adjust_view -> 3 value possible -> -1 / 0 / 1\n",
    "# Ship_health -> 0% to 100%\n",
    "# Enemy_on_radar -> 0 or 1\n",
    "# Enemy ahead -> 0 or 1\n",
    "# Time_until_you_last_locked_target -> 1sec to 200sec\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99819e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Actions that you can take\n",
    "# \"\"\"\n",
    "# If target_locked state is 1, -> Fire missile by pressing '1'\n",
    "# If there is no enemy-> make movements in the given range  // I don't know how it will move towards enemy but for now it should move randomly searching for them\n",
    "# If and only if there target_locked is negative then try to adjust the view\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2907d8ec-b521-4ff3-8d87-025ad4a319bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rewards\n",
    "# \"\"\"\n",
    "# Reward:\n",
    "# Initialized fire: +4000\n",
    "# Locked_on the enemy: +100\n",
    "# Initating lock_on the enemy: +30\n",
    "# Not_locked on: -20\n",
    "# No_enemy_on_the_radar: -100\n",
    "# If_red_bar_on_the_view: +10\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fccce6a0-2136-4b4f-9dd6-35e1eef746b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchImage(pattern_url, screenshot_url, threshold, lower_range, upper_range, rect_color):\n",
    "    # Target is in gray already preprocessed beforehand\n",
    "    pattern_cv2 = cv2.imread(pattern_url)\n",
    "    tar_gray = cv2.cvtColor(pattern_cv2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "    # Convert to HSV Color Space:\n",
    "    # screenshot_cv2 = np.array(screenshot)[:, :, ::-1].copy()\n",
    "    screenshot_cv2 = cv2.imread(screenshot_url)\n",
    "    hsv_image = cv2.cvtColor(screenshot_cv2, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "    # Define a Color Range:\n",
    "    mask = cv2.inRange(hsv_image, lower_range, upper_range)\n",
    "    \n",
    "    # Apply the Mask:\n",
    "    areas = cv2.bitwise_and(screenshot_cv2, screenshot_cv2, mask=mask)\n",
    "    \n",
    "    # Grayscale to remove noise:\n",
    "    gray_image = cv2.cvtColor(areas, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Template Matching:\n",
    "    result = cv2.matchTemplate(gray_image, tar_gray, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "    is_found = False\n",
    "    loc = np.where(result >= threshold)\n",
    "    \n",
    "    # Now Aiming is complete fire down\n",
    "    if(len(loc[0]) > 0):\n",
    "        is_found = True\n",
    "        pt = (loc[1][0], loc[0][0])  # Take the first match\n",
    "        cv2.rectangle(screenshot_cv2, pt, (pt[0] + pattern_cv2.shape[1], pt[1] + pattern_cv2.shape[0]), rect_color, 2)\n",
    "    \n",
    "    return screenshot_cv2, is_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f47c97d0-04d8-416b-8b63-72debc4534e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # AIM DETECTOR\n",
    "# result_images = []\n",
    "# for i in range(1, 7):\n",
    "#     img, is_present = matchImage(\"./images/aim_complete.png\", \"./Aim_train/\"+str(i)+\".png\", 0.25, np.array([50, 218, 183]),  np.array([175, 255, 255]), (0, 0, 255));\n",
    "#     if is_present:\n",
    "#         result_images.append(img)\n",
    "\n",
    "# for idx, result_image in enumerate(result_images, start=1):\n",
    "#     cv2.imshow(f\"Matching Result {idx}\", result_image)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07523146-6b75-4640-85ad-6f71c8e7cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def checkRadar(pattern_url, screenshot_url, threshold, lower_range, upper_range, rect_color):\n",
    "#     # Target is in gray already preprocessed beforehand\n",
    "#     pattern_cv2 = cv2.imread(pattern_url)\n",
    "#     tar_gray = cv2.cvtColor(pattern_cv2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "#     # Convert to HSV Color Space:\n",
    "#     # screenshot_cv2 = np.array(screenshot)[:, :, ::-1].copy()\n",
    "#     screenshot_cv2 = cv2.imread(screenshot_url)\n",
    "#     height, width, _ = screenshot_cv2.shape\n",
    "    \n",
    "#     # Calculate the cropping dimensions\n",
    "#     crop_top_percentage = 0.4\n",
    "#     crop_left_percentage = 0.25\n",
    "#     crop_top = int(height * crop_top_percentage)\n",
    "#     crop_left = int(width * crop_left_percentage)\n",
    "\n",
    "    \n",
    "#     # Define the cropping percentages\n",
    "#     screenshot_cv2 = screenshot_cv2[:crop_top, :crop_left]    \n",
    "    \n",
    "#     hsv_image = cv2.cvtColor(screenshot_cv2, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "#     # Define a Color Range:\n",
    "#     mask = cv2.inRange(hsv_image, lower_range, upper_range)\n",
    "    \n",
    "#     # Apply the Mask:\n",
    "#     areas = cv2.bitwise_and(screenshot_cv2, screenshot_cv2, mask=mask)\n",
    "    \n",
    "#     # Grayscale to remove noise:\n",
    "#     gray_image = cv2.cvtColor(areas, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "#     # Template Matching:\n",
    "#     result = cv2.matchTemplate(gray_image, tar_gray, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "#     is_found = False\n",
    "#     loc = np.where(result >= threshold)\n",
    "    \n",
    "#     # Now Aiming is complete fire down\n",
    "#     if(len(loc[0]) > 0):\n",
    "#         is_found = True\n",
    "#         pt = (loc[1][0], loc[0][0])  # Take the first match\n",
    "#         cv2.rectangle(screenshot_cv2, pt, (pt[0] + pattern_cv2.shape[1], pt[1] + pattern_cv2.shape[0]), rect_color, 2)\n",
    "    \n",
    "#     return screenshot_cv2, is_found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1801c54c-def3-4587-ab5a-56f93a9fa2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ENEMY \n",
    "# result_images = []\n",
    "# for i in range(1, 7):\n",
    "#     img, is_present = matchImage(\"./images/probable_enemy.png\", \"./Aim_train/\"+str(i)+\".png\", 0.85, np.array([0, 187, 230]),  np.array([0, 255, 255]), (255, 0, 0))\n",
    "#     if is_present:\n",
    "#         result_images.append(img)\n",
    "\n",
    "# for idx, result_image in enumerate(result_images, start=1):\n",
    "#     cv2.imshow(f\"Matching Result {idx}\", result_image)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1582f0c2-5875-44d3-91cf-515599991391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ENEMY ON RADAR\n",
    "# result_images = []\n",
    "# for i in range(1, 7):\n",
    "#     img, is_present = checkRadar(\"./images/radar_tracker.png\", \"./Aim_train/\"+str(i)+\".png\", 0.17, np.array([0, 187, 230]),  np.array([0, 255, 255]), (0, 255, 0))\n",
    "#     if is_present:\n",
    "#         result_images.append(img)\n",
    "\n",
    "# for idx, result_image in enumerate(result_images, start=1):\n",
    "#     cv2.imshow(f\"Matching Result {idx}\", result_image)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "369909e7-9442-4488-a57c-a83fdda32a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Collision detection\n",
    "\n",
    "# result_images = []\n",
    "# for i in range(1, 5):\n",
    "#     img, is_present = matchImage(\"./images/collide_tracker.png\", \"./Collide_train/\"+str(i)+\".png\", 0.50, np.array([0, 0, 145]),  np.array([161, 43, 255]), (0, 255, 0))\n",
    "#     if is_present:\n",
    "#         result_images.append(img)\n",
    "\n",
    "# for idx, result_image in enumerate(result_images, start=1):\n",
    "#     cv2.imshow(f\"Matching Result {idx}\", result_image)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75072870-6586-4326-985a-04e71594fdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rutwik\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "class YourEnvironment(gym.Env):\n",
    "    def __init__(self):\n",
    "        # Initialization of your environment parameters\n",
    "        self.action_space = gym.spaces.Discrete(4)  # Assuming 4 possible actions\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(11,), dtype=float)  # Assuming 10 states\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset the environment to the initial state\n",
    "        self.target_locked = 0 # Done\n",
    "        self.target_locked_time = 0 \n",
    "        self.damage_done = 0 # Can be Done\n",
    "        self.movement_horizontal = 0 # Can be Done\n",
    "        self.movement_vertical = 0 # Can be Done\n",
    "        self.adjust_view = 0 # Random\n",
    "        self.ship_health_percentage = 100.0\n",
    "        self.time_until_last_locked_target = 0 # Can be Done\n",
    "        self.enemy_on_radar = 0 # Done\n",
    "        self.red_bar_on_view = 0 # Done\n",
    "        self.reload_1 = 0\n",
    "        self.current_screenshot = None\n",
    "        self.continuous_lockon_enemy = 0\n",
    "        self.collision_time = 0\n",
    "        self.reward = 0\n",
    "\n",
    "        return self.get_state()\n",
    "\n",
    "    def step(self, action):\n",
    "        # Take a step in the environment based on the agent's action\n",
    "        self.update_states(action)\n",
    "        reward = self.calculate_reward()  # Implement your reward logic\n",
    "        done = self.check_done()  # Implement your termination logic\n",
    "        arr = ['none', 'fire', 'move', 'view'] \n",
    "        print(f\"Action: {arr[action]}, Reward: {reward}, Done: {done}, Idle Time: {self.time_until_last_locked_target}\")\n",
    "\n",
    "        return self.get_state(), reward, done, {}\n",
    "\n",
    "    def update_states(self, action):\n",
    "        # Update states based on the agent's action\n",
    "        self.current_screenshot = self.update_screenshot()\n",
    "\n",
    "        # Check if target is locked:\n",
    "        img, is_present = self.matchImage(\"./images/aim_complete.png\", 0.3, np.array([50, 218, 183]),  np.array([175, 255, 255]), (0, 0, 255))\n",
    "        self.target_locked = is_present\n",
    "        if is_present == False:\n",
    "            self.target_locked_time = 0\n",
    "        else:\n",
    "            self.target_locked_time += 1\n",
    "        \n",
    "        # Check if enemy is on radar:\n",
    "        img, is_present = self.checkRadar(\"./images/radar_tracker.png\", 0.17, np.array([0, 187, 230]),  np.array([0, 255, 255]), (0, 255, 0))\n",
    "        self.enemy_on_radar = is_present\n",
    "        \n",
    "        # Check if red bar is present:\n",
    "        img, is_present = self.matchImage(\"./images/probable_enemy.png\", 0.85, np.array([0, 187, 230]),  np.array([0, 255, 255]), (255, 0, 0))\n",
    "        self.red_bar_on_view = is_present\n",
    "        \n",
    "        if is_present == 1:\n",
    "            self.continuous_lockon_enemy += 1;\n",
    "        else:\n",
    "            self.continuous_lockon_enemy = 0;\n",
    "\n",
    "        \n",
    "        img, is_present = self.matchImage(\"./images/collide_tracker.png\", 0.50, np.array([0, 0, 145]), np.array([161, 43, 255]), (0, 255, 0))\n",
    "\n",
    "        if is_present == 1:\n",
    "            self.collision_time += 1;\n",
    "        else:\n",
    "            self.collision = 0;\n",
    "        \n",
    "        if self.target_locked != 1:\n",
    "            self.time_until_last_locked_target += 1\n",
    "\n",
    "        self.reload_1 += 1\n",
    "        if action == 0:  # Action: Do nothing\n",
    "            self.reward = 0\n",
    "            pass\n",
    "        elif action == 1: # Action: fire\n",
    "            if self.target_locked == 1 and self.reload_1 > 4:\n",
    "                self.time_until_last_locked_target = 0\n",
    "                self.reload_1 = 0\n",
    "                self.fire_key_1()\n",
    "                self.damage_done = 1\n",
    "                self.reward = 40\n",
    "        elif action == 2:  # Action: Random movements\n",
    "            if self.target_locked != 1:\n",
    "                self.reward = 0\n",
    "                self.do_random_movement()\n",
    "        elif action == 3:  # Action: Adjust view\n",
    "            if self.target_locked != 1:\n",
    "                self.reward = 0\n",
    "                self.do_random_viewing()\n",
    "\n",
    "    def get_state(self):\n",
    "        # Return the current state as a vector\n",
    "        return [\n",
    "            self.target_locked,\n",
    "            self.damage_done,\n",
    "            self.movement_horizontal,\n",
    "            self.movement_vertical,\n",
    "            self.adjust_view,\n",
    "            self.ship_health_percentage,\n",
    "            self.time_until_last_locked_target,\n",
    "            self.enemy_on_radar,\n",
    "            self.red_bar_on_view,\n",
    "            self.continuous_lockon_enemy,\n",
    "            self.collision_time\n",
    "        ]\n",
    "\n",
    "    def calculate_reward(self):\n",
    "        # Reward initialization\n",
    "        reward = self.reward\n",
    "    \n",
    "        # Check if fire is initialized\n",
    "        if self.target_locked == 1:\n",
    "            reward += 7*(self.target_locked_time)\n",
    "            reward += 30\n",
    "    \n",
    "        # Check if the enemy is on radar\n",
    "        if self.enemy_on_radar == 1:\n",
    "            reward += 10\n",
    "            \n",
    "        # Check if not locked on\n",
    "        if self.target_locked == 0:\n",
    "            reward -= 15\n",
    "    \n",
    "        # Check if no enemy on the radar\n",
    "        if self.enemy_on_radar == 0:\n",
    "            reward -= 3*(self.time_until_last_locked_target)\n",
    "    \n",
    "        # Check if red bar on the view\n",
    "        if self.red_bar_on_view == 1:\n",
    "            reward += 3*(self.continuous_lockon_enemy)\n",
    "\n",
    "        if self.collision_time == 0:\n",
    "            reward += 1\n",
    "        elif self.collision_time > 1:\n",
    "            reward -= 6\n",
    "        elif self.collision_time > 3:\n",
    "            reward -= 25\n",
    "    \n",
    "        return reward\n",
    "\n",
    "\n",
    "    def check_done(self):\n",
    "        # Implement your termination condition\n",
    "        if self.time_until_last_locked_target > 80:\n",
    "            self.reset()\n",
    "            return True  # Environment terminates when time exceeds 80\n",
    "        else:\n",
    "            return False  # Environment continues if time is less than or equal to 80\n",
    "        \n",
    "    def update_screenshot(self):\n",
    "        region = {'left': 0, 'top': 0, 'width': 950, 'height': 566}\n",
    "        with mss() as sct:\n",
    "            screenshot = sct.grab(region)\n",
    "            cur_img = Image.frombytes('RGB', screenshot.size, screenshot.rgb)\n",
    "            screenshot_cv2 = cv2.cvtColor(np.array(cur_img), cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "        return screenshot_cv2\n",
    "\n",
    "    def fire_key_1(self):\n",
    "        pyautogui.keyDown(\"Num1\")\n",
    "        time.sleep(0.1)\n",
    "        pyautogui.keyUp(\"Num1\")\n",
    "\n",
    "    def move_left(self):\n",
    "        pyautogui.keyDown(\"A\")\n",
    "        time.sleep(0.2)\n",
    "        pyautogui.keyUp(\"A\")\n",
    "\n",
    "    def move_right(self):\n",
    "        pyautogui.keyDown(\"D\")\n",
    "        time.sleep(0.2)\n",
    "        pyautogui.keyUp(\"D\")\n",
    "\n",
    "    def steer_up(self):\n",
    "        pyautogui.keyDown(\"W\")\n",
    "        time.sleep(0.1)\n",
    "        pyautogui.keyUp(\"W\")\n",
    "\n",
    "    def steer_down(self):\n",
    "        pyautogui.keyDown(\"S\")\n",
    "        time.sleep(0.1)\n",
    "        pyautogui.keyUp(\"S\")\n",
    "\n",
    "    def view_right(self, t):\n",
    "        pyautogui.keyDown(\"L\")\n",
    "        time.sleep(t)\n",
    "        pyautogui.keyUp(\"L\")\n",
    "\n",
    "    def view_left(self, t):\n",
    "        pyautogui.keyDown(\"J\")\n",
    "        time.sleep(t)\n",
    "        pyautogui.keyUp(\"J\")\n",
    "    \n",
    "    def do_random_movement(self):\n",
    "        horizontal_movement = random.choice([-1, 0, 1])\n",
    "        vertical_movement = random.choice([-1, 0, 1])\n",
    "\n",
    "        if horizontal_movement == -1:\n",
    "            self.move_left()\n",
    "        elif horizontal_movement == 1:\n",
    "            self.move_right()\n",
    "\n",
    "        if vertical_movement == -1:\n",
    "            self.steer_down()\n",
    "            self.vertical_movement = max(self.movement_vertical-1, -1)\n",
    "        elif vertical_movement == 1:\n",
    "            self.steer_up()\n",
    "            self.vertical_movement = min(self.movement_vertical+1, 2)\n",
    "\n",
    "    def do_random_viewing(self):\n",
    "        view_direction = random.choice([-1, 1])\n",
    "        if view_direction == -1:\n",
    "            self.view_left(0.2)\n",
    "        elif view_direction == 1:\n",
    "            self.view_right(0.2)\n",
    "\n",
    "    def checkRadar(self, pattern_url, threshold, lower_range, upper_range, rect_color):\n",
    "        pattern_cv2 = cv2.imread(pattern_url)\n",
    "        tar_gray = cv2.cvtColor(pattern_cv2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "        # Convert to HSV Color Space:\n",
    "        # screenshot_cv2 = np.array(screenshot)[:, :, ::-1].copy()\n",
    "        screenshot_cv2 = self.current_screenshot\n",
    "        height, width, _ = screenshot_cv2.shape\n",
    "        \n",
    "        # Calculate the cropping dimensions\n",
    "        crop_top_percentage = 0.4\n",
    "        crop_left_percentage = 0.25\n",
    "        crop_top = int(height * crop_top_percentage)\n",
    "        crop_left = int(width * crop_left_percentage)\n",
    "    \n",
    "        \n",
    "        # Define the cropping percentages\n",
    "        screenshot_cv2 = screenshot_cv2[:crop_top, :crop_left]    \n",
    "        \n",
    "        hsv_image = cv2.cvtColor(screenshot_cv2, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    \n",
    "        # Define a Color Range:\n",
    "        mask = cv2.inRange(hsv_image, lower_range, upper_range)\n",
    "        \n",
    "        # Apply the Mask:\n",
    "        areas = cv2.bitwise_and(screenshot_cv2, screenshot_cv2, mask=mask)\n",
    "        \n",
    "        # Grayscale to remove noise:\n",
    "        gray_image = cv2.cvtColor(areas, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Template Matching:\n",
    "        result = cv2.matchTemplate(gray_image, tar_gray, cv2.TM_CCOEFF_NORMED)\n",
    "    \n",
    "        is_found = False\n",
    "        loc = np.where(result >= threshold)\n",
    "        \n",
    "        # Now Aiming is complete fire down\n",
    "        if(len(loc[0]) > 0):\n",
    "            is_found = True\n",
    "            pt = (loc[1][0], loc[0][0])  # Take the first match\n",
    "            cv2.rectangle(screenshot_cv2, pt, (pt[0] + pattern_cv2.shape[1], pt[1] + pattern_cv2.shape[0]), rect_color, 2)\n",
    "        \n",
    "        return screenshot_cv2, is_found\n",
    "\n",
    "    def matchImage(self, pattern_url, threshold, lower_range, upper_range, rect_color):\n",
    "        pattern_cv2 = cv2.imread(pattern_url)\n",
    "        tar_gray = cv2.cvtColor(pattern_cv2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "        # Convert to HSV Color Space:\n",
    "        screenshot_cv2 = self.current_screenshot\n",
    "        hsv_image = cv2.cvtColor(screenshot_cv2, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    \n",
    "        # Define a Color Range:\n",
    "        mask = cv2.inRange(hsv_image, lower_range, upper_range)\n",
    "        \n",
    "        # Apply the Mask:\n",
    "        areas = cv2.bitwise_and(screenshot_cv2, screenshot_cv2, mask=mask)\n",
    "        \n",
    "        # Grayscale to remove noise:\n",
    "        gray_image = cv2.cvtColor(areas, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Template Matching:\n",
    "        result = cv2.matchTemplate(gray_image, tar_gray, cv2.TM_CCOEFF_NORMED)\n",
    "    \n",
    "        is_found = False\n",
    "        loc = np.where(result >= threshold)\n",
    "        \n",
    "        # Now Aiming is complete fire down\n",
    "        if(len(loc[0]) > 0):\n",
    "            is_found = True\n",
    "            pt = (loc[1][0], loc[0][0])  # Take the first match\n",
    "            cv2.rectangle(screenshot_cv2, pt, (pt[0] + pattern_cv2.shape[1], pt[1] + pattern_cv2.shape[0]), rect_color, 2)\n",
    "        \n",
    "        return screenshot_cv2, is_found\n",
    "\n",
    "class EpisodeTerminationCallback(BaseCallback):\n",
    "    def __init__(self, episode_limit, verbose=1):\n",
    "        super(EpisodeTerminationCallback, self).__init__(verbose)\n",
    "        self.episode_limit = episode_limit\n",
    "        self.episode_count = 0\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        self.episode_count += 1\n",
    "        if self.episode_count >= self.episode_limit:\n",
    "            self.episode_count = 0\n",
    "            print(f\"Terminating training after {self.episode_limit} episodes.\")\n",
    "            return False  # Return False to stop training\n",
    "        return True  # Return True to continue training\n",
    "\n",
    "env = YourEnvironment()\n",
    "model = PPO(\"MlpPolicy\", env, verbose=0)\n",
    "\n",
    "\n",
    "# # Train the model\n",
    "# model.learn(total_timesteps=48000, callback=episode_limit_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fe9d87d-77e3-4c21-87fd-2ac23aa69585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# episode_limit_callback = EpisodeTerminationCallback(10)\n",
    "# model = PPO.load(\"trained_model.zip\", env, verbose=0)\n",
    "# model.learn(total_timesteps=48000, callback=episode_limit_callback)\n",
    "# model.save(\"trained_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b3684b3-134b-4a8b-97ec-4fc8a9c08507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_iteration():\n",
    "    print(\"First iteration starting in 5 seconds.\")\n",
    "    time.sleep(5)\n",
    "    episode_limit_callback = EpisodeTerminationCallback(240)\n",
    "    model.learn(total_timesteps=48000, callback=episode_limit_callback)\n",
    "    model.save(\"trained_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "878405b4-1e07-4e87-9087-f534725c1be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_train(max_itr):\n",
    "    itr = 0\n",
    "    while itr < max_itr:   \n",
    "        if itr == 0:\n",
    "            time.sleep(5)\n",
    "            \n",
    "        if os.path.exists(\"trained_model.zip\"):\n",
    "            print(\"File found, starting model training on the base of the saved model.\")\n",
    "            env = YourEnvironment()\n",
    "            model = PPO.load(\"trained_model.zip\", env, verbose=0)\n",
    "            episode_limit_callback = EpisodeTerminationCallback(240)\n",
    "            model.learn(total_timesteps=48000, callback=episode_limit_callback)\n",
    "            model.save(\"trained_model.zip\")\n",
    "        else:\n",
    "            print(\"File not found, starting first iteration\")\n",
    "            first_iteration();\n",
    "        \n",
    "        itr += 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea64eab6-7f60-46af-ada4-909cd5ca76a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "time.sleep() takes exactly one argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mstart_train\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[23], line 5\u001b[0m, in \u001b[0;36mstart_train\u001b[1;34m(max_itr)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m itr \u001b[38;5;241m<\u001b[39m max_itr:   \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m itr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m----> 5\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained_model.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile found, starting model training on the base of the saved model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: time.sleep() takes exactly one argument (0 given)"
     ]
    }
   ],
   "source": [
    "start_train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4864950-81e3-46cc-a9df-9d6d8efc89e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
